---
title: "Week7"
author: "Deirdre Toher, Paul Hewson and [insert your name here]"
date: "23/03/2021"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(readr)
```

# Recap from last week: generic rule of thumb for a 95% Confidence Interval

$$\hat{\theta} \pm 2 se(\theta)$$

This rule of thumb is worth memorising. It can be really useful, whether working with written reports or when wanting a quick check on some data analysis.


## Computing CIs: an example with fake data

Repeating the example from the presentation


```{r simple_fake_data}
set.seed(6436)
N<-52
y <- rnorm(N, 50, 5)
fake <- data.frame(y=y)
fake %>%
  ggplot(aes(y)) +
  geom_histogram(binwidth = 5)
```


To rehearse the key idea, we will calculate a 95 percent confidence interval.

$$\bar{x} \pm 2 \times \mbox{standard error of the mean}$$

where 

$$\mbox{standard error of the mean} = \frac{sd}{\sqrt{n}}$$

### Exercise 1: Complete the code to calculate the confidence limits

```{r, calculate_ci_manually}
t_value <- qt(0.975, (N-1))
fake_mean <- mean(fake$y)
fake_sd <- sd(fake$y)
n <- length(fake$y)
fake_se_mean <- fake_sd/sqrt(n)# complete this calculation
lower_ci <- fake_mean-t_value*fake_se_mean# complete this calculation
upper_ci <-  fake_mean+t_value*fake_se_mean# complete this calculation
sprintf("95 percent CI for the mean: %f - %f", lower_ci, upper_ci)
```

The crude 95% confidence interval using $\pm 2 \times SE$ is (`r fake_mean-2*fake_se_mean`,
`r fake_mean+2*fake_se_mean`).

Compare your results with those you get from the R modelling routines:

```{r CI from model}
model_fake <- lm(y ~ 1, data = fake)
confint(model_fake, level=0.95)
```

Any comments or observations on the "hand" calculated 95% CI and the model calculated 95% CI?

Functions that we will use today that you may not have previously investigated are:

1. set.seed
2. sample
3. seq_along
4. seq_len
5. quantile

### Exercise 1a: Complete the code to calculate the confidence limits

Create a bootstrap estimate of the CI for the mean of the fake data. Start by doing this for 40 bootstrap samples, then increase the number of samples appropriately.

```{r}
set.seed(643)
Nb<-40
Bootmean<-rep(NA,Nb)

for(i in seq_len(Nb)){
  temp.boot<-fake$y[sample(seq_len(N),N,replace=TRUE)]
  # what is this doing?
  # you may want to break it into steps! 
  Bootmean[i]<- NA # insert correct calculation here (replace NA)
}

Bootstrap <- data.frame(Mean=Bootmean)

```

Create a histogram with binwidth of 0.5 `geom_histogram(binwidth = .5)` and also a density plot `+geom_density()`


How do these compare to the calculated values that use the calculation:

$$\hat{\theta} \pm t_{df=(n-1),\alpha/2}\times SE(\hat{\theta})$$

The kickstarter data
---------------------------

We asked you to pin datasets you find interesting on a map. One of you pinned some Kaggle based Kickstarter data.   All the information and metadata can be found by following the pin at <https://padlet.com/texhewson/zp5pj3hj5xulscxe> (it's the pin on the border between Wyoming and South Dakota)

In this example, I have downloaded the data to a folder adjacent to my working folder called data.

```{asis}
---CourseFolder
       |
       +------- scripts (My working folder, contains my Rmd files)
       |
       +------- data (Contains data files)
```

So when I load the file into R, I have to tell it where to look for the file.  `../` tells it to go up one folder.   `data/` tells it to look in the data folder.  I have also used a function from the `readr` library (called `read_csv`) which gives me a lot more control over how I load the data.  If you click on a file in the Files pane of R studio, it offers to load the data using this function. But here the command has been captured from the console and scripted.


```{r load_kickstarter, echo=FALSE}
kickstarter <- read_csv(
  "../data/ks-projects-201801.csv", 
  col_types = cols(
    currency = col_factor(levels = c(
      "AUD",  "CAD", "CHF", "DKK", "EUR", "GBP", "HKD", "JPY",
      "MXN", "NOK", "NZD", "SEK", "SGD", "USD")), 
    state = col_factor(levels = c(
      "canceled",  "failed", "live", "successful", "suspended",
      "undefined")),
    country = col_factor(levels = c(
      "AT", "AU", "BE", "CA", "CH", "DE", "DK", "ES", "FR", "GB",
      "HK", "IE", "IT", "JP", "LU", "MX", "N,0\"", "NL", "NO",
      "NZ", "SE", "SG", "US")),
    main_category = col_factor(levels =c (
      "Art", "Comics", "Crafts", "Dance", "Design", "Fashion",
      "Film & Video", "Food", "Games", "Journalism", "Music", 
      "Photography", "Publishing", "Technology", "Theater")),
    deadline = col_date(format = "%Y-%m-%d"), 
    launched = col_datetime(format = "%Y-%m-%d %H:%M:%S")
    ))
```



This is a large dataset. It may speed things up if you take a random subsample.  We will start by selecting only the kickstarter projects with at least one backer!

```{r}
kickstarter<-kickstarter[kickstarter$backers>0,] 
# this will overwrite the original dataset in R, but not in your original data file. 
```


The following code takes a random sample of 10,000 rows from the data, and then deletes the large dataset.  Feel free to reduce the sample size if your computer needs it.




```{r take_sample}
set.seed(7637) # for reproducability!
n_subsample <- 10000 # deliberately much smaller here.
index <- sample(seq_along(kickstarter$ID), n_subsample)
my_kickstarter <- kickstarter[index, ]
rm(kickstarter)
```

## Looking at the number of backers by state of project

As an example to get us started, here is a boxplot of the number of funders by the state of each project.  You might like to experiment with adding and removing the `scale_y_log10()` instruction. 

```{r backers, echo=FALSE}
my_kickstarter %>%
  ggplot(aes(x=state, y=backers)) + 
  geom_boxplot() + 
  scale_y_log10() +
  labs(title = "Number of backers by state of project",
       subtitle = "Kickstarter enabled funding calls",
       caption = "Data from Kickstarter via Kaggle",
       tag = "Figure 1") + 
  xlab("State of project") + 
  ylab("Number of backers") + 
  theme_bw()  
```


I would suggest this is challenging data to visualise well.  But it could be worth getting to grips with this because the implication is that `succesful` projects tend to have more backers than `failed` projects.


## Construct some confidence intervals using the bootstrap approach

To look at some confidence intervals, we will consider the funding goal variable.  We will first see how the distribution of funding goals varies by the main category of the funding call.

Create a set of bootstrap samples of your data and then use it to estimate confidence intervals for 

1. Mean of usd_goal_real
2. Median of usd_goal_real
3. Variance of usd_goal_real
4. Mean number of backers by the state of the project.


```{r bootstrap}
Nbootstrap<- 20 # you will need to increase this - but to how much?
means<-rep(NA,Nbootstrap)
medians<-rep(NA,Nbootstrap)

# it is important to set up these in advance of a loop
# DO NOT grow your vectors within a loop
set.seed(4363)
for(i in seq_len(Nbootstrap)){
  usevalues<-sample(seq_along(my_kickstarter$ID),size=length(my_kickstarter$ID),replace=TRUE)   # is this correct? should we have replace=TRUE or replace =FALSE?
  bootstrap.sample<-my_kickstarter[usevalues,]
  means[i]<- NA # replace NA with appropriate calculation.
  medians[i] <- NA # replace NA with appropriate calculation.
}
# what other values should be calculated and stored within the loop?

```


Plot a histogram of the values of the bootstrap means

```{r plot_means}


```

What is the 95% confidence interval of the bootstrap means?

```{r ciMeans}
# quantile(means,probs=c(.025,0.975)) # (uncomment out when ready to do the calculation)
```

Can you report this as "in line" rather within a code chunk?

How does this estimate compare to a traditional estimate of the confidence interval for the mean usd_goal_real?

What happens if you increase the number of bootstrap samples taken?


```{r plot_medians}


```


What is the 95% confidence interval of the bootstrap medians?


```{r plot_variances}


```

What is the 95% confidence interval of the bootstrap variances?


```{r plot_nbackers}


```

What is the 95% confidence interval of the bootstrap mean number of backers?

# Exercise 3

Think about the more complex scenarios that you may want to create estimates / confidence intervals for.

For example: confidence intervals for the number of backers for successful projects versus the number of backers for failed projects.

Based on this dataset; what research questions would you like to answer that bootstrapping may be a suitable approach?

